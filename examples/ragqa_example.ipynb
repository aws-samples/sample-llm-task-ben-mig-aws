{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2124a15b",
   "metadata": {},
   "source": [
    "## Benchmarking task - Q-A/RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4efddb-118f-4e85-987d-dac54bc04d23",
   "metadata": {},
   "source": [
    "#### Install python packages requested by benchmarking\n",
    "\n",
    "If you have not install the requested python libraries, uncomment the following command to run the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r ../peccyben/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645eec10",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda6544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from peccyben.qaragtask import QA_Ben, QA_Create_VDB\n",
    "from peccyben.utils import Ben_Save\n",
    "from peccyben.promptcatalog import Prompt_Template_Gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94f0b50-ff59-4e11-94e7-48dbf19bcc43",
   "metadata": {},
   "source": [
    "#### Configuration\n",
    "\n",
    "Setup your environment parameters \n",
    "\n",
    "* **BENCH_KEY**: a unique keyname for your benchmarking in this round \n",
    "* **S3_BUCKET**: the S3 buckt you created for the benchmarking    \n",
    "* **TASK_FOLDER**: the task folder you created under the S3 bucket   \n",
    "* **INPUT_FILE**: the file name of the dataset you prepared for benchmarking\n",
    "* **DOC_FILE**: the document to query \n",
    "* **VDB_NAME**: the vector db name for RAG pipeline   \n",
    "* **METRICS_LIST**: the metrics we provide for the question-answer task    \n",
    "* **BEDROCK_REGION**: the AWS region that the model benchmarking runs on Bedrock\n",
    "* **COST_FILE**: the price file used for calculating model inference cost      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b26a01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BENCH_KEY = 'PeccyBen_202503_test'\n",
    "S3_BUCKET = 'genai-sdo-llm-ben-20240310'\n",
    "TASK_FOLDER = 'ben-qa'\n",
    "INPUT_FILE = 'cuad_test_50p.csv'\n",
    "DOC_FILE = 'PACIRA_PHARMACEUTICALS_AGREEMENT.PDF'\n",
    "VDB_NAME = \"loha\"\n",
    "METRICS_LIST = ['Inference_Time','Input_Token','Output_Token','Throughput','RougeL-sum','Semantic_Similarity','BERT-F1','Toxicity',\n",
    "                                            'Answer_Correctness','Answer_similarity','Answer_Relevancy','Context_Recall','Context_Precision','Cost','Cache_Input_Token','Cache_Output_Token']\n",
    "BEDROCK_REGION = 'us-east-1'\n",
    "COST_FILE = 'bedrock_od_public.csv'\n",
    "\n",
    "Results_qa = pd.DataFrame()\n",
    "Results_qa = Results_qa.assign(metric_name=METRICS_LIST) \n",
    "Results_qa = Results_qa.set_index('metric_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d9738-3211-4b9a-a3a8-28bee20c5d68",
   "metadata": {},
   "source": [
    "#### Create a vector DB for RAG pipeline\n",
    "\n",
    "You can skip this step if you already created a vector db in the previous round of benchmarking\n",
    "\n",
    "* Embedding model: here we use Titan text embedding model on Bedrock\n",
    "* Set the chunk size and overlap size for your retriever embedding\n",
    "* Invoke **QA_Create_VDB** to create a faiss vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29aa496-c4d5-4588-832c-3e6660d267f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "\n",
    "boto3_bedrock = boto3.client(service_name=\"bedrock\", region_name=\"us-east-1\")\n",
    "boto3_bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "# Create embedding\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\", client=boto3_bedrock_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c345229d-60a6-4aab-a02b-cf357bb27bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set chunk size and create the vector db\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 100\n",
    "\n",
    "QA_Create_VDB(chunk_size,chunk_overlap,bedrock_embeddings,VDB_NAME,S3_BUCKET,DOC_FILE,TASK_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a3b8da-4a15-4329-96e8-9a5a0c69a243",
   "metadata": {},
   "source": [
    "#### Task specific setting\n",
    "\n",
    "* Configure your **prompt** in the prompt catalog (prompt_catalog.json), and configure the prompt_catalog_id\n",
    "* Set the **LLM hyperparameter** in model_kwargs. For the models on Bedrock, refer to [inferenceConfig](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference-call.html)\n",
    "* Set **LLM-judge model** for RAGAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb36fdc-2eff-461d-8771-3908c602f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_catalog_id = \"qa-1\"\n",
    "\n",
    "model_kwargs = {\n",
    "        'maxTokens': 1024, \n",
    "        'topP': 0.9, \n",
    "        'temperature': 0\n",
    "}   \n",
    "judge_model_id = \"mistral.mistral-large-2402-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f2eb61-a6bd-4195-ab5f-5e177f118848",
   "metadata": {},
   "source": [
    "#### Specify the model and other settings for benchmarking\n",
    "\n",
    "Invoke **QA_Ben** function to conduct the benchmarking for one selected model, repeat for multiple models you want to benchmark\n",
    "\n",
    "* **method**: set \"Bedrock\" for the models on Bedrock\n",
    "* **region**: configured in the previous step\n",
    "* **model_id**: specify the Model ID for the model endpoint\n",
    "* **judge_model_id**: specify LLM-judge model for RAGAS\n",
    "* **model_kwargs**: configured in previous step\n",
    "* **prompt_template**: prompt template based on the prompt configured in previous step\n",
    "* **s3_bucket**: configured in previous step\n",
    "* **file_name**: configured in previous step\n",
    "* **BENCH_KEY**: configured in previous step\n",
    "* **task_folder**: configured in previous step\n",
    "* **cost_key**: set \"public\" when using AWS public pricing to calculate the cost\n",
    "* **save_id**: the model name displayed in the report \n",
    "* **SLEEP_SEC**: you can configure \"sleep and retry\" when throtting, for example, set SLEEP_SEC = 10 to wait for 10 seconds between each inference\n",
    "* **SAMPLE_LEN**: you can configure the number of samples for inference\n",
    "* **PP_TIME**: if you want to run model inference for multiple rounds, set the number of rounds here.  \n",
    "* **cacheconf**: set \"default\" to enable Bedrock Prompt Caching in the inference, \"None\" to disable\n",
    "* **latencyOpt**: set \"optimized\" to enable Bedrock Latency Optimized Inference, \"None\" to disable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab0e98-45cd-439c-a479-77479a08b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nova-pro \n",
    "model_id = 'us.amazon.nova-pro-v1:0' \n",
    "save_id = 'nova-pro'\n",
    "\n",
    "prompt_template = Prompt_Template_Gen(model_id, prompt_catalog_id)\n",
    "#print(prompt_template)\n",
    "\n",
    "Results_qa[save_id] = QA_Ben(method=\"Bedrock\",\n",
    "                                   region=BEDROCK_REGION,\n",
    "                                   model_id=model_id,\n",
    "                                   judge_model_id=judge_model_id,\n",
    "                                   model_kwargs=model_kwargs,\n",
    "                                   prompt_template=prompt_template,\n",
    "                                   vdb_name=VDB_NAME,\n",
    "                                   s3_bucket=S3_BUCKET,\n",
    "                                   file_name=INPUT_FILE,\n",
    "                                   BENCH_KEY=BENCH_KEY,\n",
    "                                   task_folder=TASK_FOLDER,\n",
    "                                   cost_key=COST_FILE,\n",
    "                                   save_id=save_id,\n",
    "                                   SLEEP_SEC=20,SAMPLE_LEN=3,\n",
    "                                   PP_TIME=1,\n",
    "                                   cacheconf=\"None\",latencyOpt=\"None\")\n",
    "Results_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27583c69-582d-4e86-a77b-219432e67acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude 3.5v2 Sonnet\n",
    "model_id = 'us.anthropic.claude-3-5-sonnet-20241022-v2:0' \n",
    "save_id = 'Sonnet-3.5v2'\n",
    "\n",
    "prompt_template = Prompt_Template_Gen(model_id, prompt_catalog_id)\n",
    "#print(prompt_template)\n",
    "\n",
    "Results_qa[save_id] = QA_Ben(method=\"Bedrock\",\n",
    "                                   region=BEDROCK_REGION,\n",
    "                                   model_id=model_id,\n",
    "                                   judge_model_id=judge_model_id,                             \n",
    "                                   model_kwargs=model_kwargs,\n",
    "                                   prompt_template=prompt_template,\n",
    "                                   vdb_name=VDB_NAME,\n",
    "                                   s3_bucket=S3_BUCKET,\n",
    "                                   file_name=INPUT_FILE,\n",
    "                                   BENCH_KEY=BENCH_KEY,\n",
    "                                   task_folder=TASK_FOLDER,\n",
    "                                   cost_key=COST_FILE,\n",
    "                                   save_id=save_id,\n",
    "                                   SLEEP_SEC=20,SAMPLE_LEN=3,\n",
    "                                   PP_TIME=1,\n",
    "                                   cacheconf=\"None\",latencyOpt=\"None\")\n",
    "Results_qa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43d113-231d-4fe0-b16a-8e9742f8077f",
   "metadata": {},
   "source": [
    "#### Generate benchmarking report\n",
    "\n",
    "Invoke **Ben_Save** function to generate your benchmarking report and cost-performance analysis, all the results are stored in S3 bucket\n",
    "\n",
    "* **Results_qa**: the benchmarking results generated in previous step\n",
    "* **S3_BUCKET**: configured in previous step\n",
    "* **BENCH_KEY**: configured in previous step\n",
    "* **TASK_FOLDER**: configured in previous step\n",
    "* **perf_metric**: select the performance metric from the metrics list in the previous step, for cost-performance analysis, for example, to analyze the accuracy by semantic similarity score with cost, set \"Semantic_Similarity\".  \n",
    "* **top_x**: set the top x number of models you want to run the cost-performance analysis \n",
    "* **TITLE**: specify a title for the reports and charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee4805b-40c4-4ffe-b017-208e0669c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_metric = 'Semantic_Similarity'\n",
    "top_x = 5\n",
    "\n",
    "Ben_Save(Results_qa,S3_BUCKET,BENCH_KEY,TASK_FOLDER,perf_metric,top_x,'Q-A/RAG-Task')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad67e20-babc-48fe-aeed-6952e8391ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
