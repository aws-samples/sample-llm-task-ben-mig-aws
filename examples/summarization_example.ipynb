{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2124a15b",
   "metadata": {},
   "source": [
    "## Benchmarking task - Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f4456f-a4e0-48b8-8da0-523a5402b0c7",
   "metadata": {},
   "source": [
    "#### Install python packages requested by benchmarking\n",
    "\n",
    "If you have not install the requested python libraries, uncomment the following command to run the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r ../peccyben/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645eec10",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda6544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from peccyben.summarizationtask import Summ_Ben\n",
    "from peccyben.utils import Ben_Save\n",
    "from peccyben.promptcatalog import Prompt_Template_Gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fd3e57-9ea4-425a-aa1d-98767617a3aa",
   "metadata": {},
   "source": [
    "#### Configuration\n",
    "\n",
    "Setup your environment parameters \n",
    "\n",
    "* **BENCH_KEY**: a unique keyname for your benchmarking in this round \n",
    "* **S3_BUCKET**: the S3 buckt you created for the benchmarking    \n",
    "* **TASK_FOLDER**: the task folder you created under the S3 bucket   \n",
    "* **INPUT_FILE**: the file name of the dataset you prepared for benchmarking    \n",
    "* **METRICS_LIST**: the metrics we provide for the text summarization task      \n",
    "* **BEDROCK_REGION**: the AWS region that the model benchmarking runs on Bedrock\n",
    "* **COST_FILE**: the price file used for calculating model inference cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b26a01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BENCH_KEY = 'PeccyBen_202503_xsum'\n",
    "S3_BUCKET = 'genai-sdo-llm-ben-20240310'\n",
    "TASK_FOLDER = 'ben-summ'\n",
    "INPUT_FILE = 'xsum_100.csv'\n",
    "METRICS_LIST = ['Inference_Time','Input_Token','Output_Token','Throughput','RougeL-sum','Semantic_Similarity','BERT-F1','LJ_Score','Toxicity','Cost','Cache_Input_Token','Cache_Output_Token']\n",
    "BEDROCK_REGION = 'us-east-1'\n",
    "COST_FILE = 'bedrock_od_public.csv'\n",
    "\n",
    "Results_summ = pd.DataFrame()\n",
    "Results_summ = Results_summ.assign(metric_name=METRICS_LIST) \n",
    "Results_summ = Results_summ.set_index('metric_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b688d-ba2c-4415-aae6-c38c0935477a",
   "metadata": {},
   "source": [
    "#### Task specific setting\n",
    "\n",
    "* Configure your **prompt** in the prompt catalog (prompt_catalog.json), and configure the prompt_catalog_id\n",
    "* Set the **LLM hyperparameter** in model_kwargs. For the models on Bedrock, refer to [inferenceConfig](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference-call.html)\n",
    "* Set two **LLM-judge models** (judge_model_1, judge_model_2) for the LLM-judge for the summarization task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec15267-1132-453c-b58e-c3b90cfa5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_catalog_id = \"summ-1\"\n",
    "\n",
    "model_kwargs = {\n",
    "    'maxTokens': 512, \n",
    "    'topP': 0.9, \n",
    "    'temperature': 0\n",
    "}   \n",
    "\n",
    "judge_model_1 = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "judge_model_2 = \"us.deepseek.r1-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa4298d-a34a-4f88-91ce-972f4b27de3b",
   "metadata": {},
   "source": [
    "#### Specify the model and other settings for benchmarking\n",
    "\n",
    "Invoke **Summ_Ben** function to conduct the benchmarking for one selected model, repeat for multiple models you want to benchmark\n",
    "\n",
    "* **method**: set \"Bedrock\" for the models on Bedrock\n",
    "* **region**: configured in the previous step\n",
    "* **model_id**: specify the Model ID for the model endpoint\n",
    "* **jm1**: configured in previous step\n",
    "* **jm2**: configured in previous step\n",
    "* **model_kwargs**: configured in previous step\n",
    "* **prompt_template**: prompt template based on the prompt configured in previous step\n",
    "* **s3_bucket**: configured in previous step\n",
    "* **file_name**: configured in previous step\n",
    "* **BENCH_KEY**: configured in previous step\n",
    "* **task_folder**: configured in previous step\n",
    "* **cost_key**: set \"public\" when using AWS public pricing to calculate the cost\n",
    "* **save_id**: the model name displayed in the report \n",
    "* **SLEEP_SEC**: you can configure \"sleep and retry\" when throtting, for example, set SLEEP_SEC = 10 to wait for 10 seconds between each inference\n",
    "* **SAMPLE_LEN**: you can configure the number of samples for inference\n",
    "* **PP_TIME**: if you want to run model inference for multiple rounds, set the number of rounds here.  \n",
    "* **cacheconf**: set \"default\" to enable Bedrock Prompt Caching in the inference, \"None\" to disable\n",
    "* **latencyOpt**: set \"optimized\" to enable Bedrock Latency Optimized Inference, \"None\" to disable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456856b3-97c0-406e-8a77-5cd54e9b748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haiku 3.5\n",
    "model_id = 'us.anthropic.claude-3-5-haiku-20241022-v1:0' \n",
    "save_id = 'haiku-3.5'\n",
    "\n",
    "prompt_template = Prompt_Template_Gen(model_id, prompt_catalog_id)\n",
    "\n",
    "Results_summ[save_id] = Summ_Ben(method=\"Bedrock\",\n",
    "                                 region=BEDROCK_REGION,\n",
    "                                 model_id=model_id,\n",
    "                                 jm1=judge_model_1,\n",
    "                                 jm2=judge_model_2,\n",
    "                                 model_kwargs=model_kwargs,\n",
    "                                 prompt_template=prompt_template,\n",
    "                                 s3_bucket=S3_BUCKET,\n",
    "                                 file_name=INPUT_FILE,\n",
    "                                 BENCH_KEY=BENCH_KEY,\n",
    "                                 task_folder=TASK_FOLDER,\n",
    "                                 cost_key=COST_FILE,\n",
    "                                 save_id=save_id,\n",
    "                                 SLEEP_SEC=20,SAMPLE_LEN=2,\n",
    "                                 PP_TIME=2,\n",
    "                                 cacheconf=\"None\",latencyOpt=\"None\")\n",
    "\n",
    "Results_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d2470-bc71-4494-b537-6b6a58132fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nova-micro\n",
    "model_id = 'us.amazon.nova-micro-v1:0' \n",
    "save_id = 'nova-micro'\n",
    "\n",
    "prompt_template = Prompt_Template_Gen(model_id, prompt_catalog_id)\n",
    "#print(prompt_template)\n",
    "\n",
    "Results_summ[save_id] = Summ_Ben(method=\"Bedrock\",\n",
    "                                 region=BEDROCK_REGION,\n",
    "                                 model_id=model_id,\n",
    "                                 jm1=judge_model_1,\n",
    "                                 jm2=judge_model_2,\n",
    "                                 model_kwargs=model_kwargs,\n",
    "                                 prompt_template=prompt_template,\n",
    "                                 s3_bucket=S3_BUCKET,\n",
    "                                 file_name=INPUT_FILE,\n",
    "                                 BENCH_KEY=BENCH_KEY,\n",
    "                                 task_folder=TASK_FOLDER,\n",
    "                                 cost_key=COST_FILE,\n",
    "                                 save_id=save_id,\n",
    "                                 SLEEP_SEC=20,SAMPLE_LEN=2,\n",
    "                                 PP_TIME=2,\n",
    "                                 cacheconf=\"None\",latencyOpt=\"None\")\n",
    "\n",
    "Results_summ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563d69f8-1a62-412b-85d7-deaef39bdb5b",
   "metadata": {},
   "source": [
    "#### Generate benchmarking report\n",
    "\n",
    "Invoke **Ben_Save** function to generate your benchmarking report and cost-performance analysis, all the results are stored in S3 bucket\n",
    "\n",
    "* **Results_summ**: the benchmarking results generated in previous step\n",
    "* **S3_BUCKET**: configured in previous step\n",
    "* **BENCH_KEY**: configured in previous step\n",
    "* **TASK_FOLDER**: configured in previous step\n",
    "* **perf_metric**: select the performance metric from the metrics list in the previous step, for cost-performance analysis, for example, to analyze the accuracy by LLM-judge score with cost, set \"LJ_Score\".  \n",
    "* **top_x**: set the top x number of models you want to run the cost-performance analysis \n",
    "* **TITLE**: specify a title for the reports and charts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c84ac1-a16b-41d7-864e-5dc76bbe98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_metric = 'LJ_Score'\n",
    "top_x = 5\n",
    "\n",
    "Ben_Save(Results_summ,S3_BUCKET,BENCH_KEY,TASK_FOLDER,perf_metric,top_x,TITLE=\"Summarization-Task\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d89642-75a6-45ad-8719-442411b1df33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638931a2-cd47-4d2c-89f5-c3159fe2ff14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
